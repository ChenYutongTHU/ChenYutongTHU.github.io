---
layout: page
title: 
subtitle: Publications
full-width: true
---

<style>
  /* Custom style for highlighted font (for your name) */
  .yutongasauthor {
    color: #9E7BB5; 
    font-weight: bold; 
  }
  /* Custom styles for publications */
  .publication {
    display: flex;
    align-items: center;
    margin-bottom: 15px;
    padding: 20px;
    border-bottom: 1px solid #ddd;
    width: 80%;
    margin: 0 auto;
  }

  .publication .left-column {
    width: 30%;
    margin-right: 5px;
  }

  .publication .right-column {
    width: 70%;
  }

  .publication img {
    max-width: 100%;
    border-radius: 1px;
  }

  /* Custom font size and style for h2 */
  .publication h2 {
    font-size: 18px;
/*     font-family: 'Arial', sans-serif; */
    font-weight: bold;
    color: #333;
  }

  /* Custom font size and style for p */
  .publication p {
    font-size: 16px;
/*     font-family: 'Georgia', serif; */
    line-height: 1.6;
    color: #666;
  }

  /* Optional: You can add specific styles for links */
  .publication a {
    text-decoration: none;
    color: #e1b05d;
  }

  .publication a:hover {
    text-decoration: underline;
  }
</style>

<div class="publication">
  <div class="left-column">
    <img src="https://raw.githubusercontent.com/ChenYutongTHU/ChenYutongTHU.github.io/master/assets/img/splatformer.gif" alt="SplatFormer" class="publication-image">
  </div>
  <div class="right-column">
    <h2><strong>SplatFormer: Point Transformer for Robust 3D Gaussian Splatting</strong></h2>
    <p><span class="yutongasauthor">Yutong Chen</span>, Marko Mihajlovic, Xiyi Chen, Yiming Wang, Sergey Prokudin, and Siyu Tang.</p>
    <p>ICLR 2025 Spotlight.</p>
    <p>
      <a href="https://sergeyprokudin.github.io/splatformer/" target="_blank">Project page</a> | 
      <a href="https://arxiv.org/abs/2411.06390" target="_blank">arXiv</a> | 
      <a href="https://github.com/ChenYutongTHU/SplatFormer" target="_blank">Code</a>
    </p>
  </div>
</div>

<div class="publication">
  <div class="left-column">
    <img src="https://raw.githubusercontent.com/ChenYutongTHU/ChenYutongTHU.github.io/master/assets/img/dyco.gif" alt="Dyco" class="publication-image" style="margin-right: 20px; margin-left: 20px; width: 80%; height: auto;" >
  </div>
  <div class="right-column">
    <h2><strong>Within the Dynamic Context: Inertia-aware 3D Human Modeling with Pose Sequence</strong></h2>
    <p><span class="yutongasauthor">Yutong Chen</span><sup>*</sup>, Yifan Zhan<sup>*</sup>, Zhihang Zhong, Wei Wang, Xiao Sun, Yu Qiao,
Yinqiang Zheng (<sup>*</sup> indicates equal contribution)</p> 
    <p>ECCV 2024.</p>
    <p>
      <a href="https://ai4sports.opengvlab.com/Dyco/" target="_blank">Project page</a> | 
      <a href="https://arxiv.org/pdf/2403.19160" target="_blank">arXiv</a> | 
      <a href="https://github.com/Yifever20002/Dyco" target="_blank">Code</a>
    </p>
  </div>
</div>

<div class="publication">
  <div class="left-column">
    <img src="https://raw.githubusercontent.com/ChenYutongTHU/ChenYutongTHU.github.io/master/assets/img/Xsign.jpg" alt="XCross" class="publication-image">
  </div>
  <div class="right-column">
    <h2><strong>Improving continuous sign language recognition with cross-lingual signs</strong></h2>
    <p>Fangyun Wei, <span class="yutongasauthor">Yutong Chen</span><sup>*</sup></p>
    <p>ICCV 2023.</p>
    <p>
      <a href="https://arxiv.org/abs/2308.10809" target="_blank">arXiv</a> | 
    </p>
  </div>
</div>


<div class="publication">
  <div class="left-column">
    <img src="https://raw.githubusercontent.com/ChenYutongTHU/ChenYutongTHU.github.io/master/assets/img/TwoStream.png" alt="TwoStream" class="publication-image">
  </div>
  <div class="right-column">
    <h2><strong>Two-stream network for sign language recognition and translation.</strong></h2>
    <p><span class="yutongasauthor">Yutong Chen</span><sup>*</sup>, Ronglai Zuo<sup>*</sup>, Fangyun Wei<sup>*</sup>, Yu Wu, Shujie Liu, Brian Mak</p>
    <p>NeurIPS 2022 Spotlight.</p>
    <p>
      <a href="https://arxiv.org/abs/2211.01367" target="_blank">arXiv</a> | 
      <a href="https://github.com/FangyunWei/SLRT" target="_blank">code</a> 
    </p>
  </div>
</div>


<div class="publication">
  <div class="left-column">
    <img src="https://raw.githubusercontent.com/ChenYutongTHU/ChenYutongTHU.github.io/master/assets/img/simple.png" alt="SLT" class="publication-image">
  </div>
  <div class="right-column">
    <h2><strong>A simple multi-modality transfer learning baseline for sign language translation.</strong></h2>
    <p><span class="yutongasauthor">Yutong Chen</span>, Fangyun Wei, Xiao Sun, Zhirong Wu, Stephen Lin</p>
    <p>CVPR 2022.</p>
    <p>
      <a href="http://arxiv.org/abs/2203.04287" target="_blank">arXiv</a> | 
      <a href="https://github.com/FangyunWei/SLRT" target="_blank">code</a> 
    </p>
  </div>
</div>

<div class="publication">
  <div class="left-column">
    <img src="https://github.com/ChenYutongTHU/ChenYutongTHU.github.io/blob/master/assets/img/manipulate.png" alt="ObjCen" class="publication-image">
  </div>
  <div class="right-column">
    <h2><strong>Learning to manipulate individual objects in an image.</strong></h2>
    <p>Yanchao Yang<sup>*</sup>, <span class="yutongasauthor">Yutong Chen</span><sup>*</sup>, Stefano Soatto</p>
    <p>CVPR 2022.</p>
    <p>
      <a href="https://arxiv.org/pdf/2004.05495" target="_blank">arXiv</a> | 
      <a href="https://github.com/ChenYutongTHU/Learning-to-manipulate-individual-objects-in-an-image-Implementation" target="_blank">code</a> 
    </p>
  </div>
</div>

